{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# self write tools\n",
    "from tools import LABEL_ENCODER, transforms_train, transforms_test\n",
    "from models import CNN, RNN, NN\n",
    "from dataset import CnnDataset, TestDataset, CREATE_CNN_TRAIN_ITERATOR, CREATE_CNN_VALID_ITERATOR, words, TEST_DATASET"
   ]
  },
  {
   "source": [
    "# Check GPU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"Using {}: {}\".format(device, torch.cuda.get_device_name(0)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Global Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 512\n",
    "EPOCHS = 100\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# 2. Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (image, (description, l), features, y) in iterator:\n",
    "\n",
    "        features = features.to(device, dtype=torch.float)\n",
    "\n",
    "  \n",
    "\n",
    "        y = y.to(device, dtype=torch.int64)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred = model(features)\n",
    "        \n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate_cnn(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (image, (description, l), features, y) in iterator:\n",
    "\n",
    "            features = features.to(device, dtype=torch.float)\n",
    "\n",
    "            y = y.to(device, dtype=torch.int64)\n",
    "                    \n",
    "            y_pred = model(features)\n",
    "            \n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_train_iterator = CREATE_CNN_TRAIN_ITERATOR(transforms_train, BATCH_SIZE)\n",
    "cnn_valid_iterator = CREATE_CNN_VALID_ITERATOR(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "model = NN(input_size=4, hidden_size=15, output_size=27).cuda()\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "valid_acc_list = []\n",
    "valid_loss_list = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    # train\n",
    "    train_loss, train_acc = train(model, cnn_train_iterator, optimizer, criterion, device)\n",
    "    \n",
    "    # valid\n",
    "    valid_loss, valid_acc = evaluate_cnn(model, cnn_valid_iterator, criterion, device)\n",
    "\n",
    "    # save best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'output/linear-model.pt')\n",
    "\n",
    "    # Track the accuracy\n",
    "    train_accuracy_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_acc_list.append(valid_acc)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "        \n",
    "    # print epoch info\n",
    "    end_time = time.monotonic()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        \n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('output/linear-model.pt'))\n",
    "test_loss, test_acc = evaluate_cnn(model, cnn_valid_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}