{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# self write tools\n",
    "from tools import LABEL_ENCODER, transforms_train, transforms_test\n",
    "from models import CNN, RNN, NN\n",
    "from dataset import CnnDataset, TestDataset, CREATE_CNN_TRAIN_ITERATOR, CREATE_CNN_VALID_ITERATOR, words, TEST_DATASET"
   ]
  },
  {
   "source": [
    "# Check GPU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"Using {}: {}\".format(device, torch.cuda.get_device_name(0)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda: GeForce RTX 3080\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, _cnn, _rnn, _nn):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.cnn = _cnn\n",
    "        self.rnn = _rnn\n",
    "        self.nn = _nn\n",
    "        self.classifier2 = nn.Linear(81, 200)\n",
    "        self.classifier1 = nn.Linear(200, 100)\n",
    "        self.classifier = nn.Linear(100, 27)\n",
    "        \n",
    "    def forward(self, image, description, l, features):\n",
    "        x1 = self.cnn(image)\n",
    "        x2 = self.rnn(description, l)\n",
    "        x3 = self.nn(features)\n",
    "\n",
    "\n",
    "        x = torch.cat((x1, x2, x3), dim=1)\n",
    "        x = self.classifier2(F.relu(x))\n",
    "        x = self.classifier1(F.relu(x))\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "source": [
    "# Global Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 50\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# 2. Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (image, (description, l), features, y) in iterator:\n",
    "\n",
    "        description = description.to(device, dtype=torch.long)\n",
    "        # l = l.to(device, dtype=torch.long)\n",
    "        l = l.long()\n",
    "        \n",
    "        image = image.to(device)\n",
    "        features = features.to(device)\n",
    "        y = y.to(device, dtype=torch.int64)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        # y_pred = model(image)\n",
    "        y_pred = model(image, description, l, features)\n",
    "        \n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate_cnn(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (image, (description, l), features, y) in iterator:\n",
    "\n",
    "            description = description.to(device, dtype=torch.long)\n",
    "            # l = l.to(device, dtype=torch.long)\n",
    "            l = l.long()\n",
    "            \n",
    "            image = image.to(device)\n",
    "            features = features.to(device)\n",
    "        \n",
    "            y = y.to(device, dtype=torch.int64)\n",
    "                    \n",
    "            # y_pred = model(image)\n",
    "            y_pred = model(image, description, l, features)\n",
    "            \n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_train_iterator = CREATE_CNN_TRAIN_ITERATOR(transforms_train, BATCH_SIZE)\n",
    "cnn_valid_iterator = CREATE_CNN_VALID_ITERATOR(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "\n",
    "cnn_model = CNN()\n",
    "cnn_model = cnn_model.cuda()\n",
    "cnn_model.load_state_dict(torch.load('output/cnn-model.pt'))\n",
    "\n",
    "\n",
    "rnn_model = RNN()\n",
    "rnn_model = rnn_model.cuda()\n",
    "rnn_model.load_state_dict(torch.load('output/rnn-model.pt'))\n",
    "# test_loss, test_acc = evaluate_cnn(rnn_model, cnn_valid_iterator, criterion, device)\n",
    "# print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
    "\n",
    "nn_model = NN(4, 15, 27)\n",
    "nn_model = nn_model.cuda()\n",
    "nn_model.load_state_dict(torch.load('output/linear-model.pt'))\n",
    "\n",
    "ensamble_model = MyEnsemble(cnn_model, rnn_model, nn_model)\n",
    "ensamble_model = ensamble_model.cuda()\n",
    "\n",
    "# model = cnn_model\n",
    "model = ensamble_model\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Loss: 0.124 | Test Acc: 97.51%\n",
      "Epoch: 01 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.006 | Train Acc: 99.80%\n",
      "\t Val. Loss: 0.141 |  Val. Acc: 97.35%\n",
      "Epoch: 02 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.85%\n",
      "\t Val. Loss: 0.139 |  Val. Acc: 97.30%\n",
      "Epoch: 03 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.83%\n",
      "\t Val. Loss: 0.142 |  Val. Acc: 97.44%\n",
      "Epoch: 04 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.006 | Train Acc: 99.87%\n",
      "\t Val. Loss: 0.132 |  Val. Acc: 97.48%\n",
      "Epoch: 05 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.93%\n",
      "\t Val. Loss: 0.150 |  Val. Acc: 97.19%\n",
      "Epoch: 06 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.91%\n",
      "\t Val. Loss: 0.144 |  Val. Acc: 97.29%\n",
      "Epoch: 07 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.90%\n",
      "\t Val. Loss: 0.135 |  Val. Acc: 97.37%\n",
      "Epoch: 08 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.91%\n",
      "\t Val. Loss: 0.152 |  Val. Acc: 97.19%\n",
      "Epoch: 09 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.006 | Train Acc: 99.84%\n",
      "\t Val. Loss: 0.163 |  Val. Acc: 96.74%\n",
      "Epoch: 10 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.86%\n",
      "\t Val. Loss: 0.152 |  Val. Acc: 97.22%\n",
      "Epoch: 11 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.84%\n",
      "\t Val. Loss: 0.157 |  Val. Acc: 96.97%\n",
      "Epoch: 12 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.86%\n",
      "\t Val. Loss: 0.157 |  Val. Acc: 97.11%\n",
      "Epoch: 13 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.89%\n",
      "\t Val. Loss: 0.152 |  Val. Acc: 97.13%\n",
      "Epoch: 14 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.86%\n",
      "\t Val. Loss: 0.143 |  Val. Acc: 97.16%\n",
      "Epoch: 15 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.90%\n",
      "\t Val. Loss: 0.147 |  Val. Acc: 97.27%\n",
      "Epoch: 16 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.83%\n",
      "\t Val. Loss: 0.160 |  Val. Acc: 97.16%\n",
      "Epoch: 17 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.89%\n",
      "\t Val. Loss: 0.173 |  Val. Acc: 96.93%\n",
      "Epoch: 18 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.006 | Train Acc: 99.85%\n",
      "\t Val. Loss: 0.150 |  Val. Acc: 96.97%\n",
      "Epoch: 19 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.006 | Train Acc: 99.86%\n",
      "\t Val. Loss: 0.141 |  Val. Acc: 97.34%\n",
      "Epoch: 20 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.93%\n",
      "\t Val. Loss: 0.141 |  Val. Acc: 97.30%\n",
      "Epoch: 21 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.94%\n",
      "\t Val. Loss: 0.147 |  Val. Acc: 97.34%\n",
      "Epoch: 22 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.97%\n",
      "\t Val. Loss: 0.133 |  Val. Acc: 97.53%\n",
      "Epoch: 23 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.001 | Train Acc: 99.98%\n",
      "\t Val. Loss: 0.142 |  Val. Acc: 97.44%\n",
      "Epoch: 24 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.001 | Train Acc: 99.96%\n",
      "\t Val. Loss: 0.143 |  Val. Acc: 97.36%\n",
      "Epoch: 25 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.002 | Train Acc: 99.94%\n",
      "\t Val. Loss: 0.164 |  Val. Acc: 97.09%\n",
      "Epoch: 26 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.87%\n",
      "\t Val. Loss: 0.159 |  Val. Acc: 96.99%\n",
      "Epoch: 27 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.90%\n",
      "\t Val. Loss: 0.151 |  Val. Acc: 97.12%\n",
      "Epoch: 28 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.006 | Train Acc: 99.82%\n",
      "\t Val. Loss: 0.181 |  Val. Acc: 96.59%\n",
      "Epoch: 29 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.88%\n",
      "\t Val. Loss: 0.163 |  Val. Acc: 96.92%\n",
      "Epoch: 30 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.002 | Train Acc: 99.92%\n",
      "\t Val. Loss: 0.153 |  Val. Acc: 97.00%\n",
      "Epoch: 31 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.93%\n",
      "\t Val. Loss: 0.160 |  Val. Acc: 97.18%\n",
      "Epoch: 32 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.002 | Train Acc: 99.95%\n",
      "\t Val. Loss: 0.169 |  Val. Acc: 97.18%\n",
      "Epoch: 33 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.91%\n",
      "\t Val. Loss: 0.145 |  Val. Acc: 97.60%\n",
      "Epoch: 34 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.92%\n",
      "\t Val. Loss: 0.168 |  Val. Acc: 97.23%\n",
      "Epoch: 35 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.92%\n",
      "\t Val. Loss: 0.150 |  Val. Acc: 97.17%\n",
      "Epoch: 36 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.002 | Train Acc: 99.94%\n",
      "\t Val. Loss: 0.148 |  Val. Acc: 97.42%\n",
      "Epoch: 37 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.002 | Train Acc: 99.95%\n",
      "\t Val. Loss: 0.153 |  Val. Acc: 97.35%\n",
      "Epoch: 38 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.001 | Train Acc: 99.96%\n",
      "\t Val. Loss: 0.151 |  Val. Acc: 97.67%\n",
      "Epoch: 39 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.001 | Train Acc: 99.97%\n",
      "\t Val. Loss: 0.164 |  Val. Acc: 97.31%\n",
      "Epoch: 40 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.001 | Train Acc: 99.97%\n",
      "\t Val. Loss: 0.162 |  Val. Acc: 97.20%\n",
      "Epoch: 41 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.002 | Train Acc: 99.94%\n",
      "\t Val. Loss: 0.161 |  Val. Acc: 97.28%\n",
      "Epoch: 42 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.88%\n",
      "\t Val. Loss: 0.157 |  Val. Acc: 97.04%\n",
      "Epoch: 43 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.005 | Train Acc: 99.87%\n",
      "\t Val. Loss: 0.148 |  Val. Acc: 97.03%\n",
      "Epoch: 44 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.004 | Train Acc: 99.87%\n",
      "\t Val. Loss: 0.156 |  Val. Acc: 97.04%\n",
      "Epoch: 45 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.93%\n",
      "\t Val. Loss: 0.151 |  Val. Acc: 97.15%\n",
      "Epoch: 46 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.93%\n",
      "\t Val. Loss: 0.157 |  Val. Acc: 97.14%\n",
      "Epoch: 47 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.93%\n",
      "\t Val. Loss: 0.158 |  Val. Acc: 97.22%\n",
      "Epoch: 48 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.002 | Train Acc: 99.93%\n",
      "\t Val. Loss: 0.151 |  Val. Acc: 97.10%\n",
      "Epoch: 49 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.001 | Train Acc: 99.97%\n",
      "\t Val. Loss: 0.168 |  Val. Acc: 97.17%\n",
      "Epoch: 50 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.003 | Train Acc: 99.93%\n",
      "\t Val. Loss: 0.158 |  Val. Acc: 97.20%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.load_state_dict(torch.load('output/combine-model.pt'))\n",
    "test_loss, test_acc = evaluate_cnn(model, cnn_valid_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')\n",
    "\n",
    "\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "valid_acc_list = []\n",
    "valid_loss_list = []\n",
    "# best_valid_loss = float('inf')\n",
    "best_valid_loss = test_loss\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    # train\n",
    "    train_loss, train_acc = train(model, cnn_train_iterator, optimizer, criterion, device)\n",
    "    \n",
    "    # valid\n",
    "    valid_loss, valid_acc = evaluate_cnn(model, cnn_valid_iterator, criterion, device)\n",
    "\n",
    "    # save best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        print('Best Epoch:', epoch)\n",
    "        print('Best Accuracy:', valid_acc)\n",
    "        print('Best Loss:', valid_loss)\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'output/combine-model.pt')\n",
    "\n",
    "    # Track the accuracy\n",
    "    train_accuracy_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_acc_list.append(valid_acc)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "        \n",
    "    # print epoch info\n",
    "    end_time = time.monotonic()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Loss: 0.12453 | Test Acc: 97.50280%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('output/combine-model.pt'))\n",
    "test_loss, test_acc = evaluate_cnn(model, cnn_valid_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.5f} | Test Acc: {test_acc*100:.5f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    dataloader = DataLoader(TEST_DATASET, batch_size=1024)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    model.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (images, (description, l), ids, features) in tqdm(dataloader):\n",
    "\n",
    "            description = description.to(device, dtype=torch.long)\n",
    "                # l = l.to(device, dtype=torch.long)\n",
    "            l = l.long()\n",
    "                \n",
    "            images = images.to(device)\n",
    "            features = features.to(device)\n",
    "            \n",
    "                        \n",
    "            y_pred = model(images, description, l, features)\n",
    "            \n",
    "\n",
    "            top_pred = y_pred.argmax(1).cpu()\n",
    "            labels = LABEL_ENCODER.inverse_transform(top_pred)\n",
    "\n",
    "            temp = pd.DataFrame()\n",
    "            temp['id'] = ids\n",
    "            temp['category'] = labels\n",
    "            \n",
    "\n",
    "            df = df.append(temp)\n",
    "\n",
    "\n",
    "    print(df)\n",
    "    df.to_csv('output/prediction.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 22/22 [00:11<00:00,  1.90it/s]        id   category\n",
      "0    26266  Innerwear\n",
      "1    22134    Topwear\n",
      "2    28358      Belts\n",
      "3    15554      Shoes\n",
      "4    53408  Innerwear\n",
      "..     ...        ...\n",
      "119  39737    Eyewear\n",
      "120  57477      Dress\n",
      "121  22312    Topwear\n",
      "122  54105       Lips\n",
      "123  14080       Bags\n",
      "\n",
      "[21628 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}