{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<IPython.core.display.Javascript object>",
      "application/javascript": "if (window.IPython && IPython.notebook.kernel) IPython.notebook.kernel.execute('jovian.utils.jupyter.get_notebook_name_saved = lambda: \"' + IPython.notebook.notebook_name + '\"')"
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "      id  category  gender  baseColour  season  usage  \\\n0  47381        21       4           2       3      0   \n1  13218        24       2          45       2      2   \n2  41776        24       4          31       0      0   \n3  56271        12       2          25       2      0   \n4  27361         9       2          32       1      0   \n\n                              noisyTextDescription  \\\n0                              HM Women Blue Flats   \n1                     Arrow Men Yellow Danny Shirt   \n2  Chhota Bheem Kids Qsm I Love to red Pink Tshirt   \n3           Jockey Textura Men Pack Of 2 Duet 1010   \n4                         Wild stone Men Juice Deo   \n\n                                       description  description_length  \\\n0                              HM Women Blue Flats                   4   \n1                     Arrow Men Yellow Danny Shirt                   5   \n2  Chhota Bheem Kids Qsm I Love to red Pink Tshirt                  10   \n3           Jockey Textura Men Pack Of 2 Duet 1010                   8   \n4                         Wild stone Men Juice Deo                   5   \n\n                                             encoded  \n0  [[1827, 3, 44, 210, 0, 0, 0, 0, 0, 0, 0, 0, 0,...  \n1  [[54, 22, 373, 1261, 42, 0, 0, 0, 0, 0, 0, 0, ...  \n2  [[3044, 3113, 258, 2184, 476, 582, 335, 172, 2...  \n3  [[280, 1688, 22, 243, 96, 9, 825, 51, 0, 0, 0,...  \n4  [[466, 3370, 22, 4127, 462, 0, 0, 0, 0, 0, 0, ...  \n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# self write tools\n",
    "from tools import LABEL_ENCODER, transforms_train, transforms_test\n",
    "from models import CNN, RNN\n",
    "from dataset import CnnDataset, TestDataset, CREATE_CNN_TRAIN_ITERATOR, CREATE_CNN_VALID_ITERATOR, words, TEST_DATASET\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Check GPU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"Using {}: {}\".format(device, torch.cuda.get_device_name(0)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda: GeForce RTX 3080\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Global Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 40\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self, _cnn, _rnn):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        self.cnn = _cnn\n",
    "        self.rnn = _rnn\n",
    "        self.classifier2 = nn.Linear(54, 54)\n",
    "        self.classifier1 = nn.Linear(54, 54)\n",
    "        self.classifier = nn.Linear(54, 27)\n",
    "        \n",
    "    def forward(self, image, description, l):\n",
    "        x1 = self.cnn(image, description, l)\n",
    "        x2 = self.rnn(description, l)\n",
    "\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.classifier2(F.relu(x))\n",
    "        x = self.classifier1(F.relu(x))\n",
    "        x = self.classifier(F.relu(x))\n",
    "        return x"
   ]
  },
  {
   "source": [
    "# 2. Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (image, (description, l), features, y) in iterator:\n",
    "\n",
    "        description = description.to(device, dtype=torch.long)\n",
    "        # l = l.to(device, dtype=torch.long)\n",
    "        l = l.long()\n",
    "        \n",
    "        image = image.to(device)\n",
    "        y = y.to(device, dtype=torch.int64)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        # y_pred = model(image)\n",
    "        y_pred = model(image)\n",
    "        \n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate_cnn(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (image, (description, l), features, y) in iterator:\n",
    "\n",
    "            description = description.to(device, dtype=torch.long)\n",
    "\n",
    "            l = l.long()\n",
    "            \n",
    "            image = image.to(device)\n",
    "        \n",
    "            y = y.to(device, dtype=torch.int64)\n",
    "                    \n",
    "            y_pred = model(image)\n",
    "            \n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_train_iterator = CREATE_CNN_TRAIN_ITERATOR(transforms_train, BATCH_SIZE)\n",
    "cnn_valid_iterator = CREATE_CNN_VALID_ITERATOR(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = CrossEntropyLoss()\n",
    "criterion = criterion.cuda()\n",
    "\n",
    "\n",
    "\n",
    "cnn_model = CNN()\n",
    "cnn_model = cnn_model.cuda()\n",
    "\n",
    "\n",
    "model = cnn_model\n",
    "\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 36s\n",
      "\tTrain Loss: 1.008 | Train Acc: 75.42%\n",
      "\t Val. Loss: 0.402 |  Val. Acc: 89.30%\n",
      "Epoch: 02 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.327 | Train Acc: 90.84%\n",
      "\t Val. Loss: 0.290 |  Val. Acc: 92.14%\n",
      "Epoch: 03 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.222 | Train Acc: 93.50%\n",
      "\t Val. Loss: 0.278 |  Val. Acc: 92.02%\n",
      "Epoch: 04 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.163 | Train Acc: 95.16%\n",
      "\t Val. Loss: 0.282 |  Val. Acc: 92.07%\n",
      "Epoch: 05 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.130 | Train Acc: 96.00%\n",
      "\t Val. Loss: 0.264 |  Val. Acc: 93.14%\n",
      "Epoch: 06 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.098 | Train Acc: 97.01%\n",
      "\t Val. Loss: 0.296 |  Val. Acc: 92.41%\n",
      "Epoch: 07 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.086 | Train Acc: 97.32%\n",
      "\t Val. Loss: 0.295 |  Val. Acc: 93.30%\n",
      "Epoch: 08 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.073 | Train Acc: 97.69%\n",
      "\t Val. Loss: 0.304 |  Val. Acc: 92.85%\n",
      "Epoch: 09 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.064 | Train Acc: 97.93%\n",
      "\t Val. Loss: 0.301 |  Val. Acc: 92.87%\n",
      "Epoch: 10 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.060 | Train Acc: 98.20%\n",
      "\t Val. Loss: 0.299 |  Val. Acc: 93.35%\n",
      "Epoch: 11 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.053 | Train Acc: 98.32%\n",
      "\t Val. Loss: 0.293 |  Val. Acc: 93.44%\n",
      "Epoch: 12 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.049 | Train Acc: 98.52%\n",
      "\t Val. Loss: 0.319 |  Val. Acc: 93.77%\n",
      "Epoch: 13 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.044 | Train Acc: 98.58%\n",
      "\t Val. Loss: 0.332 |  Val. Acc: 92.89%\n",
      "Epoch: 14 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.037 | Train Acc: 98.80%\n",
      "\t Val. Loss: 0.352 |  Val. Acc: 93.11%\n",
      "Epoch: 15 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.037 | Train Acc: 98.88%\n",
      "\t Val. Loss: 0.318 |  Val. Acc: 93.77%\n",
      "Epoch: 16 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.040 | Train Acc: 98.85%\n",
      "\t Val. Loss: 0.336 |  Val. Acc: 93.41%\n",
      "Epoch: 17 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.034 | Train Acc: 98.85%\n",
      "\t Val. Loss: 0.338 |  Val. Acc: 93.33%\n",
      "Epoch: 18 | Epoch Time: 0m 31s\n",
      "\tTrain Loss: 0.033 | Train Acc: 99.07%\n",
      "\t Val. Loss: 0.350 |  Val. Acc: 93.39%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "valid_acc_list = []\n",
    "valid_loss_list = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "best_epoch = 0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    # train\n",
    "    train_loss, train_acc = train(model, cnn_train_iterator, optimizer, criterion, device)\n",
    "    \n",
    "    # valid\n",
    "    valid_loss, valid_acc = evaluate_cnn(model, cnn_valid_iterator, criterion, device)\n",
    "\n",
    "    # save best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_epoch = epoch\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'output/cnn-model.pt')\n",
    "        \n",
    "\n",
    "    # Track the accuracy\n",
    "    train_accuracy_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_acc_list.append(valid_acc)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "        \n",
    "    # print epoch info\n",
    "    end_time = time.monotonic()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "    \n",
    "    if train_acc*100 > 99:\n",
    "        break\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Best Epoch: 4\n"
     ]
    }
   ],
   "source": [
    "print('Best Epoch:', best_epoch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Loss: 0.264 | Test Acc: 93.14%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('output/cnn-model.pt'))\n",
    "test_loss, test_acc = evaluate_cnn(model, cnn_valid_iterator, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "def predict(model):\n",
    "    dataloader = DataLoader(TEST_DATASET, batch_size=1024)\n",
    "\n",
    "    df = pd.DataFrame()\n",
    "    model.eval()\n",
    "        \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (images, (description, l), ids) in tqdm(dataloader):\n",
    "\n",
    "            description = description.to(device, dtype=torch.long)\n",
    "                # l = l.to(device, dtype=torch.long)\n",
    "            l = l.long()\n",
    "                \n",
    "            images = images.to(device)\n",
    "            \n",
    "                        \n",
    "            y_pred = model(images, description, l)\n",
    "            \n",
    "\n",
    "            top_pred = y_pred.argmax(1).cpu()\n",
    "            labels = LABEL_ENCODER.inverse_transform(top_pred)\n",
    "\n",
    "            temp = pd.DataFrame()\n",
    "            temp['id'] = ids\n",
    "            temp['category'] = labels\n",
    "            \n",
    "\n",
    "            df = df.append(temp)\n",
    "\n",
    "\n",
    "    print(df)\n",
    "    df.to_csv('output/cnn_prediction.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}