{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "source": [
    "# Check GPU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"Using {}: {}\".format(device, torch.cuda.get_device_name(0)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "source": [
    "# Global Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = 'input/images/'\n",
    "TRAIN_CSV = 'input/split/train.csv'\n",
    "VALID_CSV = 'input/split/valid.csv'\n",
    "BATCH_SIZE = 256\n",
    "\n",
    "LABEL_ENCODER = LabelEncoder()\n",
    "LABEL_ENCODER.fit(pd.read_csv(\"input/train.csv\")['category'])\n",
    "\n"
   ]
  },
  {
   "source": [
    "# 1. Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_dict():\n",
    "    train_data = pd.read_csv('input/train.csv')\n",
    "    train_y = train_data['category'].values\n",
    "    categories = list(set(train_y))\n",
    "    categories_dict = { categories[i]: i for i in range(27)}\n",
    "    return categories_dict\n",
    "\n",
    "class ProductDataset(Dataset):\n",
    "\n",
    "    def __init__(self, df, transforms=None, X=None, Y=None):\n",
    "        self.df = df\n",
    "        self.category_dict = get_category_dict()\n",
    "        self.transforms=transforms\n",
    "        \n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "        # print('init:', len(self.X), len(self.Y))\n",
    "\n",
    "    def __len__(self):\n",
    "        # print('len: ', len(self.X))\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # print('idx:', idx)\n",
    "\n",
    "        image_path = IMAGES_DIR + str(self.X[idx]) + '.jpg'\n",
    "        image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        if self.transforms:\n",
    "            transformed = self.transforms(image=image)\n",
    "            image = transformed['image']\n",
    "        \n",
    "        # label_text = self.Y[idx]\n",
    "        # label = self.category_dict[label_text]\n",
    "        # label = torch.from_numpy(np.array([label]).astype(np.int8))\n",
    "        \n",
    "        return image, self.Y[idx]"
   ]
  },
  {
   "source": [
    "## 1.1 Split data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "df = pd.read_csv(\"input/train.csv\")\n",
    "\n",
    "X = list(df['id'])\n",
    "y = list(df['category'])\n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "y_train, y_valid = LABEL_ENCODER.transform(y_train), LABEL_ENCODER.transform(y_valid)\n",
    "\n",
    "\n",
    "train_df = None\n",
    "test_df = None\n",
    "\n",
    "len(X_valid), len(y_valid)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_train = A.Compose([\n",
    "    # A.Flip(),\n",
    "    A.ShiftScaleRotate(rotate_limit=1.0, p=0.8),\n",
    "\n",
    "    # Pixels\n",
    "    A.OneOf([\n",
    "        A.IAAEmboss(p=1.0),\n",
    "        A.IAASharpen(p=1.0),\n",
    "        A.Blur(p=1.0),\n",
    "    ], p=0.5),\n",
    "\n",
    "    # Affine\n",
    "    # A.OneOf([\n",
    "    #     A.ElasticTransform(p=1.0),\n",
    "    #     A.IAAPiecewiseAffine(p=1.0)\n",
    "    # ], p=0.5),\n",
    "\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "\n",
    "transforms_test = A.Compose([\n",
    "    A.Normalize(p=1.0),\n",
    "    ToTensorV2(p=1.0),\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = ProductDataset(train_df, transforms_train, X_train, y_train)\n",
    "test_dataset = ProductDataset(test_df, transforms_test, X_valid, y_valid)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# 2. Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_classes=27):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.backbone = torchvision.models.wide_resnet101_2(pretrained=True)\n",
    "        \n",
    "        in_features = self.backbone.fc.in_features\n",
    "\n",
    "        self.logit = nn.Linear(in_features, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        batch_size, C, H, W = x.shape\n",
    "        \n",
    "        x = self.backbone.conv1(x)\n",
    "        x = self.backbone.bn1(x)\n",
    "        x = self.backbone.relu(x)\n",
    "        x = self.backbone.maxpool(x)\n",
    "\n",
    "        x = self.backbone.layer1(x)\n",
    "        x = self.backbone.layer2(x)\n",
    "        x = self.backbone.layer3(x)\n",
    "        x = self.backbone.layer4(x)\n",
    "        \n",
    "        x = F.adaptive_avg_pool2d(x,1).reshape(batch_size,-1)\n",
    "        x = F.dropout(x, 0.25, self.training)\n",
    "\n",
    "        x = self.logit(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = criterion.cuda()\n"
   ]
  },
  {
   "source": [
    "# 3. Train"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device, dtype=torch.int64)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device, dtype=torch.int64)\n",
    "                    \n",
    "            y_pred = model(x)\n",
    "            \n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "max_epochs = 20\n",
    "train_accuracy_list = []\n",
    "train_loss_list = []\n",
    "valid_acc_list = []\n",
    "valid_loss_list = []\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "for epoch in range(max_epochs):\n",
    "\n",
    "    start_time = time.monotonic()\n",
    "\n",
    "    # train\n",
    "    train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, device)\n",
    "    \n",
    "    # valid\n",
    "    valid_loss, valid_acc = evaluate(model, test_dataloader, criterion, device)\n",
    "\n",
    "    # save best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model.state_dict(), 'output/cnn-model.pt')\n",
    "\n",
    "    # Track the accuracy\n",
    "    train_accuracy_list.append(train_acc)\n",
    "    train_loss_list.append(train_loss)\n",
    "    valid_acc_list.append(valid_acc)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "        \n",
    "    # print epoch info\n",
    "    end_time = time.monotonic()\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./output/cnn-model.pt'))\n",
    "\n",
    "test_loss, test_acc = evaluate(model, test_dataloader, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, iterator, device):\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    images = []\n",
    "    labels = []\n",
    "    probs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "\n",
    "            x = x.to(device)\n",
    "\n",
    "            y_pred = model(x)\n",
    "\n",
    "            y_prob = F.softmax(y_pred, dim = -1)\n",
    "            top_pred = y_prob.argmax(1, keepdim = True)\n",
    "\n",
    "            images.append(x.cpu())\n",
    "            labels.append(y.cpu())\n",
    "            probs.append(y_prob.cpu())\n",
    "\n",
    "    images = torch.cat(images, dim = 0)\n",
    "    labels = torch.cat(labels, dim = 0)\n",
    "    probs = torch.cat(probs, dim = 0)\n",
    "\n",
    "    return images, labels, probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels, probs = get_predictions(model, test_dataloader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_labels = torch.argmax(probs, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(labels, pred_labels, classes):\n",
    "    \n",
    "    fig = plt.figure(figsize = (15, 15));\n",
    "    ax = fig.add_subplot(1, 1, 1);\n",
    "    cm = confusion_matrix(labels, pred_labels);\n",
    "\n",
    "\n",
    "    for i in range(27):\n",
    "        total = sum(cm[i])\n",
    "\n",
    "        for j in range(27):\n",
    "            cm[i][j] = (cm[i][j] / total) * 100\n",
    "        # if cm[i][i] > 15:\n",
    "        #     cm[i][i] = 15\n",
    "\n",
    "\n",
    "\n",
    "    cm = ConfusionMatrixDisplay(cm, display_labels = classes);\n",
    "    cm.plot(values_format = 'd', cmap = 'Blues', ax = ax)\n",
    "    plt.xticks(rotation = 20)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(labels, pred_labels, get_category_dict().keys()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}