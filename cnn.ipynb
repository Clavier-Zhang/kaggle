{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "# for reading and displaying images\n",
    "from skimage.io import imread\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "# for creating validation set\n",
    "from sklearn.model_selection import train_test_split\n",
    "# for evaluating the model\n",
    "from sklearn.metrics import accuracy_score\n",
    "from tqdm import tqdm\n",
    "# PyTorch libraries and modules\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout\n",
    "\n",
    "\n",
    "from torch.optim import Adam, SGD\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import time\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "# self write tools\n",
    "from tools import LABEL_ENCODER, transforms_train, transforms_test\n",
    "from models import CNN\n",
    "from dataset import CnnDataset, TestDataset"
   ]
  },
  {
   "source": [
    "# Check GPU"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda\" if cuda else \"cpu\")\n",
    "torch.backends.cudnn.benchmark = True\n",
    "print(\"Using {}: {}\".format(device, torch.cuda.get_device_name(0)))"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Using cuda: GeForce RTX 3080\n"
     ]
    }
   ]
  },
  {
   "source": [
    "# Global Variables"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGES_DIR = 'input/images/'\n",
    "TRAIN_CSV = 'input/split/train.csv'\n",
    "VALID_CSV = 'input/split/valid.csv'\n",
    "\n",
    "BATCH_SIZE = 256\n",
    "EPOCHS = 20\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "source": [
    "# Load Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_cnn_iterator(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    X = list(df['id'])\n",
    "    y = list(df['category'])\n",
    "\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=11)\n",
    "\n",
    "    y_train, y_valid = LABEL_ENCODER.transform(y_train), LABEL_ENCODER.transform(y_valid)\n",
    "\n",
    "\n",
    "    train_dataset = CnnDataset(transforms_train, X_train, y_train)\n",
    "    test_dataset = CnnDataset(transforms_test, X_valid, y_valid)\n",
    "\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    return train_dataloader, test_dataloader\n",
    "\n",
    "train_dataloader, test_dataloader = create_cnn_iterator(\"input/train.csv\")"
   ]
  },
  {
   "source": [
    "# 2. Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs\n",
    "\n",
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    for (x, y) in iterator:\n",
    "        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device, dtype=torch.int64)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "                \n",
    "        y_pred = model(x)\n",
    "        \n",
    "        \n",
    "        loss = criterion(y_pred, y)\n",
    "        \n",
    "        acc = calculate_accuracy(y_pred, y)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate_cnn(model, iterator, criterion, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "\n",
    "        for (x, y) in iterator:\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device, dtype=torch.int64)\n",
    "                    \n",
    "            y_pred = model(x)\n",
    "            \n",
    "            loss = criterion(y_pred, y)\n",
    "            \n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN()\n",
    "optimizer = Adam(model.parameters(), lr=0.0001)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "model = model.cuda()\n",
    "criterion = criterion.cuda()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# train_accuracy_list = []\n",
    "# train_loss_list = []\n",
    "# valid_acc_list = []\n",
    "# valid_loss_list = []\n",
    "# best_valid_loss = float('inf')\n",
    "\n",
    "# for epoch in range(EPOCHS):\n",
    "\n",
    "#     start_time = time.monotonic()\n",
    "\n",
    "#     # train\n",
    "#     train_loss, train_acc = train(model, train_dataloader, optimizer, criterion, device)\n",
    "    \n",
    "#     # valid\n",
    "#     valid_loss, valid_acc = evaluate_cnn(model, test_dataloader, criterion, device)\n",
    "\n",
    "#     # save best model\n",
    "#     if valid_loss < best_valid_loss:\n",
    "#         best_valid_loss = valid_loss\n",
    "#         torch.save(model.state_dict(), 'output/cnn-model.pt')\n",
    "\n",
    "#     # Track the accuracy\n",
    "#     train_accuracy_list.append(train_acc)\n",
    "#     train_loss_list.append(train_loss)\n",
    "#     valid_acc_list.append(valid_acc)\n",
    "#     valid_loss_list.append(valid_loss)\n",
    "        \n",
    "#     # print epoch info\n",
    "#     end_time = time.monotonic()\n",
    "#     epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "#     print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "#     print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "#     print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Loss: 0.245 | Test Acc: 92.82%\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('output/cnn-model.pt'))\n",
    "test_loss, test_acc = evaluate_cnn(model, test_dataloader, criterion, device)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.3f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "100%|██████████| 22/22 [00:11<00:00,  1.88it/s]        id   category\n",
      "0    26266      Dress\n",
      "1    22134    Topwear\n",
      "2    28358      Belts\n",
      "3    15554      Shoes\n",
      "4    53408  Innerwear\n",
      "..     ...        ...\n",
      "119  39737    Eyewear\n",
      "120  57477      Dress\n",
      "121  22312    Topwear\n",
      "122  54105       Lips\n",
      "123  14080       Bags\n",
      "\n",
      "[21628 rows x 2 columns]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.read_csv('input/test.csv')\n",
    "\n",
    "test_dataset = TestDataset(test_df)\n",
    "\n",
    "dataloader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "model.eval()\n",
    "    \n",
    "with torch.no_grad():\n",
    "\n",
    "    for (ids, images) in tqdm(dataloader):\n",
    "            \n",
    "        images = images.to(device)\n",
    "        \n",
    "                    \n",
    "        y_pred = model(images)\n",
    "        \n",
    "\n",
    "        top_pred = y_pred.argmax(1).cpu()\n",
    "        labels = LABEL_ENCODER.inverse_transform(top_pred)\n",
    "\n",
    "        temp = pd.DataFrame()\n",
    "        temp['id'] = ids\n",
    "        temp['category'] = labels\n",
    "        \n",
    "\n",
    "        df = df.append(temp)\n",
    "\n",
    "\n",
    "print(df)\n",
    "df.to_csv('output/cnn_prediction.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}